{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pA2qneaWMJmN"
      },
      "source": [
        "## Installs and Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "collapsed": true,
        "id": "RPcbxBQR9Kkb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9100a448-9ad4-49ef-9038-b320debc1f98"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.5.1+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.10.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.20.1+cu121)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.26.4)\n",
            "Requirement already satisfied: torch==2.5.1 in /usr/local/lib/python3.10/dist-packages (from torchvision) (2.5.1+cu121)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (11.0.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch==2.5.1->torchvision) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.5.1->torchvision) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.5.1->torchvision) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.5.1->torchvision) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch==2.5.1->torchvision) (2024.10.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch==2.5.1->torchvision) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch==2.5.1->torchvision) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch==2.5.1->torchvision) (3.0.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install librosa\n",
        "!pip install torch\n",
        "!pip install torchvision"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "WzxColJcFbvy"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import librosa\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, Dataset, random_split\n",
        "from torchvision import transforms\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision.transforms import Normalize\n",
        "import torch.optim as optim\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchvision import models\n",
        "from sklearn.model_selection import train_test_split\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jew9OELFuGyl",
        "outputId": "cef9b8ac-9a64-4d2f-a9a0-b8c46636a62a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GDx2_XibuOK_",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "# GTZN Dataset Import\n",
        "# Create Shortcut into your own drive: https://drive.google.com/file/d/12Ls4CNeMIPsOZTEqztT06RChdfBRjUBm/view?usp=sharing\n",
        "!cp /content/drive/MyDrive/archive.zip /content\n",
        "!unzip /content/archive.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1ejTX7GmUH_s",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "# FMA Small Dataset Import, Unzip\n",
        "# Create Shortcut into your own drive : https://drive.google.com/file/d/1Z5jTAKZW3ng4ztg9OkOMY5FkLeZ-tpkt/view\n",
        "!cp /content/drive/MyDrive/mel_spectograms.zip /content\n",
        "!unzip /content/mel_spectograms.zip"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yHuMgOzhOAfu"
      },
      "source": [
        "## Dataset Prep"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "4lIwSI3k9IEw"
      },
      "outputs": [],
      "source": [
        "# This Code is used to declare the class to prepare the GTZAN Dataset\n",
        "class GenreDatasetGTZAN(Dataset):\n",
        "    def __init__(self, root_dir, transform=None):\n",
        "        self.data = []\n",
        "        self.labels = []\n",
        "        self.genre_to_label = {\n",
        "            \"blues\": 0, \"classical\": 1, \"country\": 2, \"disco\": 3,\n",
        "            \"hiphop\": 4, \"jazz\": 5, \"metal\": 6, \"pop\": 7, \"reggae\": 8, \"rock\": 9\n",
        "        }\n",
        "        self.transform = transform\n",
        "\n",
        "        for genre, label in self.genre_to_label.items():\n",
        "            genre_dir = os.path.join(root_dir, genre)\n",
        "            for file in os.listdir(genre_dir):\n",
        "                if file.endswith(\".wav\"):\n",
        "                    file_path = os.path.join(genre_dir, file)\n",
        "                    try:\n",
        "                        librosa.load(file_path, duration=1)\n",
        "                        self.data.append(file_path)\n",
        "                        self.labels.append(label)\n",
        "                    except Exception as e:\n",
        "                        print(f\"Skipping invalid file: {file_path}\")\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        file_path = self.data[idx]\n",
        "        label = self.labels[idx]\n",
        "        try:\n",
        "            y_audio, sr = librosa.load(file_path, duration=30)\n",
        "        except Exception as e:\n",
        "            return None, None\n",
        "        mel_spec = librosa.feature.melspectrogram(y=y_audio, sr=sr)\n",
        "        mel_spec_db = librosa.power_to_db(mel_spec, ref=np.max)\n",
        "        mel_spec_resized = librosa.util.fix_length(mel_spec_db, size=2048, axis=1)\n",
        "        mel_spec_resized = mel_spec_resized[:128, :]\n",
        "        sample = torch.tensor(mel_spec_resized, dtype=torch.float32).unsqueeze(0)\n",
        "        if self.transform:\n",
        "            sample = self.transform(sample)\n",
        "\n",
        "        return sample, label\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JLk8AImNB8Dl"
      },
      "outputs": [],
      "source": [
        "# This Code is used to declare the class to prepare the Free Music Archive Dataset\n",
        "class GenreDatasetFMA(Dataset):\n",
        "    def __init__(self, root_dir, transform=None):\n",
        "        self.data = []\n",
        "        self.labels = []\n",
        "        self.genre_to_label = {genre: idx for idx, genre in enumerate(sorted(os.listdir(root_dir)))}\n",
        "        self.transform = transform\n",
        "\n",
        "        # Load files\n",
        "        for genre, label in self.genre_to_label.items():\n",
        "            genre_dir = os.path.join(root_dir, genre)\n",
        "            for file in os.listdir(genre_dir):\n",
        "                if file.endswith(\".npy\"):\n",
        "                    file_path = os.path.join(genre_dir, file)\n",
        "                    self.data.append(file_path)\n",
        "                    self.labels.append(label)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        file_path = self.data[idx]\n",
        "        label = self.labels[idx]\n",
        "\n",
        "        try:\n",
        "            mel_spec = np.load(file_path)\n",
        "            mel_spec = mel_spec[:128, :2048]\n",
        "            sample = torch.tensor(mel_spec, dtype=torch.float32).unsqueeze(0)\n",
        "\n",
        "            if self.transform:\n",
        "                sample = self.transform(sample)\n",
        "\n",
        "            return sample, label\n",
        "\n",
        "        except Exception as e:\n",
        "            return None, None\n",
        "\n",
        "# We are using a custom collate Function since we encountered a few problematic files in the FMA Dataset\n",
        "def custom_collate(batch):\n",
        "    # Filter out None entries\n",
        "    batch = [item for item in batch if item is not None]\n",
        "\n",
        "    if len(batch) == 0:\n",
        "        return None, None\n",
        "\n",
        "    try:\n",
        "        inputs, labels = zip(*batch)\n",
        "\n",
        "        # Remove inputs with NaN values\n",
        "        valid_inputs_labels = []\n",
        "        for input_tensor, label in zip(inputs, labels):\n",
        "            if torch.isnan(input_tensor).any():\n",
        "                continue\n",
        "            valid_inputs_labels.append((input_tensor, label))\n",
        "\n",
        "        if len(valid_inputs_labels) == 0:\n",
        "            return None, None\n",
        "\n",
        "        inputs, labels = zip(*valid_inputs_labels)\n",
        "        inputs = torch.stack(inputs)\n",
        "        labels = torch.tensor(labels)\n",
        "\n",
        "        return inputs, labels\n",
        "\n",
        "    except Exception as ex:\n",
        "        return None, None"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AEWQjKKykyf0"
      },
      "source": [
        "## RESNET 18\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "07SUEGHXkKrk"
      },
      "outputs": [],
      "source": [
        "# Define Resnet\n",
        "class ResNet18GenreClassifier(nn.Module):\n",
        "    def __init__(self, num_classes):\n",
        "        super(ResNet18GenreClassifier, self).__init__()\n",
        "        self.resnet = models.resnet18(pretrained=True)\n",
        "        self.resnet.conv1 = nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
        "        self.resnet.fc = nn.Linear(self.resnet.fc.in_features, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.resnet(x)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "AidpgjCzkrDA"
      },
      "outputs": [],
      "source": [
        "\n",
        "#Code to Train Model and Evaluate Model - Used for Both ResNet and Traditional CNN\n",
        "def train_model(model, train_loader, criterion, optimizer, device, epochs=10):\n",
        "    model.train()\n",
        "    for epoch in range(epochs):\n",
        "        running_loss = 0.0\n",
        "        for inputs, labels in train_loader:\n",
        "            if inputs is None or labels is None:\n",
        "                continue\n",
        "\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            running_loss += loss.item()\n",
        "\n",
        "        if len(train_loader) > 0:\n",
        "            print(f\"Epoch {epoch + 1}/{epochs}, Loss: {running_loss / len(train_loader):.4f}\")\n",
        "\n",
        "def evaluate_model(model, test_loader, device):\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in test_loader:\n",
        "            if inputs is None or labels is None:\n",
        "                continue\n",
        "\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            outputs = model(inputs)\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "    if total > 0:\n",
        "        accuracy = correct / total\n",
        "        print(f\"Test Accuracy: {accuracy:.4f}\")\n",
        "    else:\n",
        "        print(\"No valid test samples found\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### GTZAN - ResNet"
      ],
      "metadata": {
        "id": "RgHaFecjnHh7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0x43pQgWNM3J",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "# Split dataset into train and test sets for GTZAN\n",
        "dataset = GenreDatasetGTZAN(root_dir='/content/Data/genres_original', transform=None)\n",
        "train_indices, test_indices = train_test_split(list(range(len(dataset))), test_size=0.2, random_state=42)\n",
        "train_sampler = torch.utils.data.SubsetRandomSampler(train_indices)\n",
        "test_sampler = torch.utils.data.SubsetRandomSampler(test_indices)\n",
        "train_loader = DataLoader(dataset, batch_size=32, sampler=train_sampler, num_workers=2)\n",
        "test_loader = DataLoader(dataset, batch_size=32, sampler=test_sampler, num_workers=2)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "36sAg3fgkr0X",
        "outputId": "4b8e8197-5a6a-4b2a-ed84-cc10d2353b41"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15, Loss: 1.5494\n",
            "Epoch 2/15, Loss: 0.8599\n",
            "Epoch 3/15, Loss: 0.5928\n",
            "Epoch 4/15, Loss: 0.3803\n",
            "Epoch 5/15, Loss: 0.2446\n",
            "Epoch 6/15, Loss: 0.1742\n",
            "Epoch 7/15, Loss: 0.1336\n",
            "Epoch 8/15, Loss: 0.0880\n",
            "Epoch 9/15, Loss: 0.0636\n",
            "Epoch 10/15, Loss: 0.0435\n",
            "Epoch 11/15, Loss: 0.0361\n",
            "Epoch 12/15, Loss: 0.0403\n",
            "Epoch 13/15, Loss: 0.0459\n",
            "Epoch 14/15, Loss: 0.0264\n",
            "Epoch 15/15, Loss: 0.0205\n",
            "Test Accuracy: 0.8350\n"
          ]
        }
      ],
      "source": [
        "EPOCHS = 15\n",
        "# Initialize model, criterion, and optimizer\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = ResNet18GenreClassifier(num_classes=10).to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=5e-5)\n",
        "train_model(model, train_loader, criterion, optimizer, device, epochs=EPOCHS)\n",
        "accuracy = evaluate_model(model, test_loader, device)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "save_path = \"resnet_genre_classifier_gtzan.pth\"\n",
        "torch.save(model.state_dict(), save_path)"
      ],
      "metadata": {
        "id": "ybyTz9c5fg-k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### FMA - ResNet"
      ],
      "metadata": {
        "id": "2eZQZSKUnACN"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "xAqWUNzgkdxr"
      },
      "outputs": [],
      "source": [
        "# Split dataset into train and test sets for FMA\n",
        "class NormalizeSpectrogram:\n",
        "    def __call__(self, sample):\n",
        "        return (sample - sample.mean()) / (sample.std() + 1e-5)\n",
        "\n",
        "transform = NormalizeSpectrogram()\n",
        "dataset = GenreDatasetFMA(root_dir='/content/kaggle/working/mel_spectrograms', transform=transform)\n",
        "\n",
        "train_indices, test_indices = train_test_split(list(range(len(dataset))), test_size=0.2, random_state=42)\n",
        "train_sampler = torch.utils.data.SubsetRandomSampler(train_indices)\n",
        "test_sampler = torch.utils.data.SubsetRandomSampler(test_indices)\n",
        "train_loader = DataLoader(dataset, batch_size=32, sampler=train_sampler, num_workers=2, collate_fn=custom_collate)\n",
        "test_loader = DataLoader(dataset, batch_size=32, sampler=test_sampler, num_workers=2, collate_fn=custom_collate)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RZ3Zs6Uy6NPh",
        "outputId": "21af2725-dece-4a70-9c07-75b44cf8e95f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10, Loss: 1.3384\n",
            "Epoch 2/10, Loss: 1.0144\n",
            "Epoch 3/10, Loss: 0.8264\n",
            "Epoch 4/10, Loss: 0.6363\n",
            "Epoch 5/10, Loss: 0.4668\n",
            "Epoch 6/10, Loss: 0.2924\n",
            "Epoch 7/10, Loss: 0.1697\n",
            "Epoch 8/10, Loss: 0.0981\n",
            "Epoch 9/10, Loss: 0.0538\n",
            "Epoch 10/10, Loss: 0.0342\n",
            "Test Accuracy: 0.6044\n"
          ]
        }
      ],
      "source": [
        "EPOCHS = 10\n",
        "# Initialize model, criterion, and optimizer\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = ResNet18GenreClassifier(num_classes=8).to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=5e-5)\n",
        "train_model(model, train_loader, criterion, optimizer, device, epochs=EPOCHS)\n",
        "accuracy = evaluate_model(model, test_loader, device)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-SnMS0rktcY4"
      },
      "outputs": [],
      "source": [
        "save_path = \"resnet_genre_classifier_fma.pth\"\n",
        "torch.save(model.state_dict(), save_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Traditional CNN\n"
      ],
      "metadata": {
        "id": "ZpaRxK7chvtB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ConvNeuralNetwork(nn.Module):\n",
        "    def __init__(self, num_classes):\n",
        "        super(ConvNeuralNetwork, self).__init__()\n",
        "        self.conv_layers = nn.Sequential(\n",
        "            nn.Conv2d(1, 8, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "\n",
        "            nn.Conv2d(8, 16, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "            nn.Conv2d(16, 32, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "\n",
        "            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "\n",
        "            nn.Conv2d(64, 64, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        )\n",
        "\n",
        "        self.fc_layers = nn.Sequential(\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(64 * 4 * 64, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(128, 64),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(64, num_classes)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv_layers(x)\n",
        "        x = self.fc_layers(x)\n",
        "        return x\n"
      ],
      "metadata": {
        "id": "Joz4HLZbhyZb"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Traditional CNN - GTZAN"
      ],
      "metadata": {
        "id": "UroPUAqF6JDs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Split dataset into train and test sets for GTZAN\n",
        "dataset = GenreDatasetGTZAN(root_dir='/content/Data/genres_original', transform=None)\n",
        "train_indices, test_indices = train_test_split(list(range(len(dataset))), test_size=0.2, random_state=42)\n",
        "train_sampler = torch.utils.data.SubsetRandomSampler(train_indices)\n",
        "test_sampler = torch.utils.data.SubsetRandomSampler(test_indices)\n",
        "train_loader = DataLoader(dataset, batch_size=32, sampler=train_sampler, num_workers=2)\n",
        "test_loader = DataLoader(dataset, batch_size=32, sampler=test_sampler, num_workers=2)\n"
      ],
      "metadata": {
        "id": "nFKIeDIoicP3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "EPOCHS = 10\n",
        "# Initialize model, criterion, and optimizer\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = ConvNeuralNetwork(num_classes=10).to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=5e-4)\n",
        "train_model(model, train_loader, criterion, optimizer, device, epochs=EPOCHS)\n",
        "accuracy = evaluate_model(model, test_loader, device)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6ytY2divtpLD",
        "outputId": "fee45236-001d-4b39-92b0-00010276e4ad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10, Loss: 2.3133\n",
            "Epoch 2/10, Loss: 2.2409\n",
            "Epoch 3/10, Loss: 2.0828\n",
            "Epoch 4/10, Loss: 1.9959\n",
            "Epoch 5/10, Loss: 1.7912\n",
            "Epoch 6/10, Loss: 1.6417\n",
            "Epoch 7/10, Loss: 1.5343\n",
            "Epoch 8/10, Loss: 1.4093\n",
            "Epoch 9/10, Loss: 1.3440\n",
            "Epoch 10/10, Loss: 1.2545\n",
            "Test Accuracy: 0.5000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
        "train_model(model, train_loader, criterion, optimizer, device, epochs=10)\n",
        "accuracy = evaluate_model(model, test_loader, device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qcgtFZ8eSiqv",
        "outputId": "f8f6ddc9-33c4-4788-ab67-d1a0fc71ed20"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10, Loss: 0.8533\n",
            "Epoch 2/10, Loss: 0.7868\n",
            "Epoch 3/10, Loss: 0.7644\n",
            "Epoch 4/10, Loss: 0.7440\n",
            "Epoch 5/10, Loss: 0.7197\n",
            "Epoch 6/10, Loss: 0.7051\n",
            "Epoch 7/10, Loss: 0.6933\n",
            "Epoch 8/10, Loss: 0.6741\n",
            "Epoch 9/10, Loss: 0.6473\n",
            "Epoch 10/10, Loss: 0.6320\n",
            "Test Accuracy: 0.5750\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = optim.Adam(model.parameters(), lr=2e-4)\n",
        "train_model(model, train_loader, criterion, optimizer, device, epochs=5)\n",
        "accuracy = evaluate_model(model, test_loader, device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BhL3K3BPWaEU",
        "outputId": "b41c757d-a8cd-4c03-bee8-94474b2b40d6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5, Loss: 0.5125\n",
            "Epoch 2/5, Loss: 0.5236\n",
            "Epoch 3/5, Loss: 0.4925\n",
            "Epoch 4/5, Loss: 0.4239\n",
            "Epoch 5/5, Loss: 0.3944\n",
            "Test Accuracy: 0.6250\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Traditional CNN - FMA\n"
      ],
      "metadata": {
        "id": "8sE1wGWCmd5u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Split dataset into train and test sets for FMA\n",
        "class NormalizeSpectrogram:\n",
        "    def __call__(self, sample):\n",
        "        return (sample - sample.mean()) / (sample.std() + 1e-6)\n",
        "\n",
        "transform = NormalizeSpectrogram()\n",
        "dataset = GenreDatasetFMA(root_dir='/content/kaggle/working/mel_spectrograms', transform=transform)\n",
        "\n",
        "train_indices, test_indices = train_test_split(list(range(len(dataset))), test_size=0.2, random_state=42)\n",
        "train_sampler = torch.utils.data.SubsetRandomSampler(train_indices)\n",
        "test_sampler = torch.utils.data.SubsetRandomSampler(test_indices)\n",
        "train_loader = DataLoader(dataset, batch_size=32, sampler=train_sampler, num_workers=2, collate_fn=custom_collate)\n",
        "test_loader = DataLoader(dataset, batch_size=32, sampler=test_sampler, num_workers=2, collate_fn=custom_collate)\n"
      ],
      "metadata": {
        "id": "QcprRpa5miVB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "EPOCHS = 55\n",
        "# Initialize model, criterion, and optimizer\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "fma_cnn_model = ConvNeuralNetwork(num_classes=8).to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(fma_cnn_model.parameters(), lr=5e-5)\n",
        "train_model(fma_cnn_model, train_loader, criterion, optimizer, device, epochs=EPOCHS)\n",
        "accuracy = evaluate_model(fma_cnn_model, test_loader, device)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e4513pK5mlTZ",
        "outputId": "12353eeb-aaf8-4b51-bda0-191d273c13ef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/25, Loss: 1.9342\n",
            "Epoch 2/25, Loss: 1.8092\n",
            "Epoch 3/25, Loss: 1.6857\n",
            "Epoch 4/25, Loss: 1.6192\n",
            "Epoch 5/25, Loss: 1.5767\n",
            "Epoch 6/25, Loss: 1.5412\n",
            "Epoch 7/25, Loss: 1.5187\n",
            "Epoch 8/25, Loss: 1.5027\n",
            "Epoch 9/25, Loss: 1.4738\n",
            "Epoch 10/25, Loss: 1.4650\n",
            "Epoch 11/25, Loss: 1.4455\n",
            "Epoch 12/25, Loss: 1.4405\n",
            "Epoch 13/25, Loss: 1.4398\n",
            "Epoch 14/25, Loss: 1.4117\n",
            "Epoch 15/25, Loss: 1.4063\n",
            "Epoch 16/25, Loss: 1.4041\n",
            "Epoch 17/25, Loss: 1.3832\n",
            "Epoch 18/25, Loss: 1.3711\n",
            "Epoch 19/25, Loss: 1.3529\n",
            "Epoch 20/25, Loss: 1.3534\n",
            "Epoch 21/25, Loss: 1.3373\n",
            "Epoch 22/25, Loss: 1.3208\n",
            "Epoch 23/25, Loss: 1.3087\n",
            "Epoch 24/25, Loss: 1.3010\n",
            "Epoch 25/25, Loss: 1.2927\n",
            "Test Accuracy: 0.4688\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = optim.Adam(fma_cnn_model.parameters(), lr=1e-3)\n",
        "train_model(fma_cnn_model, train_loader, criterion, optimizer, device, epochs=5)\n",
        "accuracy = evaluate_model(fma_cnn_model, test_loader, device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WprVr1aqrdwF",
        "outputId": "bb60f3ba-588b-4a53-dee2-9a36126f856f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5, Loss: 1.5855\n",
            "Epoch 2/5, Loss: 1.3792\n",
            "Epoch 3/5, Loss: 1.2639\n",
            "Epoch 4/5, Loss: 1.1623\n",
            "Epoch 5/5, Loss: 1.0031\n",
            "Test Accuracy: 0.5027\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "save_path = \"cnn_genre_classifier_fma.pth\"\n",
        "torch.save(model.state_dict(), save_path)"
      ],
      "metadata": {
        "id": "bcdvpqfyryP2"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "7H1ZEi-snI57",
        "AEWQjKKykyf0",
        "jwdhAgb4o7Ys",
        "3BkN98FkBZ5X"
      ],
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}